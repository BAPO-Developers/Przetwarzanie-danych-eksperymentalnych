{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85342f5f-3eef-4418-bf84-9d8014aa6f1a",
   "metadata": {},
   "source": [
    "# Eksperyment i porównanie modeli regresji liniowej, regularyzacji Ridge (grzbietowa), Lasso oraz SVM\n",
    "W celu przeprowadzenia poprawnie eksperymentu należy wykonać walidację krzyżową, czyli dokonać kilkukrotnego podziału na zbiór uczący i treningowy. Zbadane zostaną cztery modele w imprementacji `sklearn`:\n",
    "regresja liniowa, regularyzacja Lasso, regularyzacja grzbietowa (Ridge) oraz SVM dla przypadku regresji czyli Support Vector Regression. Początkowo wykonano implementacje wszystkich modeli z parametrami domyślnymi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f675032-3a1d-4bd8-89ba-099bde232c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from Goal import goal_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8e5581-5102-4802-9f44-647bceea8b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE dla LinReg    wynosi 3.628\n",
      "MAE dla Ridge     wynosi 3.632\n",
      "MAE dla Lasso     wynosi 5.616\n",
      "MAE dla SVR       wynosi 3.186\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data.xlsx')\n",
    "np.random.seed(1410)\n",
    "\n",
    "clfs = {\n",
    "    'LinReg   ': LinearRegression(),\n",
    "    'Ridge    ': Ridge(),\n",
    "    'Lasso    ': Lasso(),\n",
    "    'SVR      ': SVR()\n",
    "}\n",
    "\n",
    "# Walidacja krzyżowa\n",
    "times_cross_validation = 3\n",
    "kf = KFold(n_splits=times_cross_validation, shuffle=True, random_state=1410)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = df.drop(columns=['PE'])\n",
    "y = df['PE']\n",
    "result_basic = np.zeros((times_cross_validation, len(clfs)))\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for j, clf_key in enumerate(clfs):\n",
    "        clf = copy.deepcopy(clfs[clf_key])\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        result_basic[i, j] = mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "for i, clf_key in enumerate(clfs):\n",
    "    print(f'MAE dla {clf_key} wynosi {round(result_basic[:,i].mean(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd2aa57-ca33-4e31-965e-ec0f9677116b",
   "metadata": {},
   "source": [
    "Następnie powtórzono eksperyment z wyznaczonymi wcześniej parametrami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea10147-bc01-4edd-b441-3292adcbea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE dla LinReg    wynosi 3.628\n",
      "MAE dla Ridge     wynosi 3.625\n",
      "MAE dla Lasso     wynosi 3.629\n",
      "MAE dla SVR       wynosi 3.169\n"
     ]
    }
   ],
   "source": [
    "ridge_param = {'alpha': -1.4950000000000534, 'solver': 'auto', 'random_state': 46}\n",
    "lasso_param = {'alpha': 0.01, 'fit_intercept': True, 'max_iter': 700, 'random_state': 46}\n",
    "svr_param = {'C': 1.3, 'epsilon': 0.11}\n",
    "\n",
    "clfs = {\n",
    "    'LinReg   ': LinearRegression(),\n",
    "    'Ridge    ': Ridge(**ridge_param),\n",
    "    'Lasso    ': Lasso(**lasso_param),\n",
    "    'SVR      ': SVR(**svr_param)\n",
    "}\n",
    "\n",
    "np.random.seed(1410)\n",
    "times_cross_validation = 3\n",
    "kf = KFold(n_splits=times_cross_validation, shuffle=True, random_state=1410)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = df.drop(columns=['PE'])\n",
    "y = df['PE']\n",
    "result_tun = np.zeros((times_cross_validation, len(clfs)))\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for j, clf_key in enumerate(clfs):\n",
    "        clf = copy.deepcopy(clfs[clf_key])\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        result_tun[i, j] = mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "for i, clf_key in enumerate(clfs):\n",
    "    print(f'MAE dla {clf_key} wynosi {round(result_tun[:,i].mean(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a52c2-bb9c-40fa-adcf-ca9f8292e76d",
   "metadata": {},
   "source": [
    "Kolejnym punktem było zaszumienie danych i przetestowanie działania algorytmów. W tym celu każda wartość przemnożono raz wartośc wylosowaną z rozkładu normalnego o wartości oczekiwanej 1 i odchyleniu standardowym o wartości 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b11ffae-924f-4a6f-a5b2-73418e712438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data.xlsx')\n",
    "columns_name = np.array(df.columns)\n",
    "noise = np.random.normal(1, 0.1, [len(columns_name), len(df)])\n",
    "for i, name in enumerate(columns_name):\n",
    "    df[name] = df[name]*noise[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ad62f0-5db3-4a8d-b509-e7a143d27510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE dla LinReg    wynosi 35.915\n",
      "MAE dla Ridge     wynosi 35.915\n",
      "MAE dla Lasso     wynosi 35.915\n",
      "MAE dla SVR       wynosi 35.974\n"
     ]
    }
   ],
   "source": [
    "ridge_param = {'alpha': -1.4950000000000534, 'solver': 'auto', 'random_state': 46}\n",
    "lasso_param = {'alpha': 0.01, 'fit_intercept': True, 'max_iter': 700, 'random_state': 46}\n",
    "svr_param = {'C': 1.3, 'epsilon': 0.11}\n",
    "\n",
    "clfs = {\n",
    "    'LinReg   ': LinearRegression(),\n",
    "    'Ridge    ': Ridge(**ridge_param),\n",
    "    'Lasso    ': Lasso(**lasso_param),\n",
    "    'SVR      ': SVR(**svr_param)\n",
    "}\n",
    "\n",
    "np.random.seed(1410)\n",
    "times_cross_validation = 3\n",
    "kf = KFold(n_splits=times_cross_validation, shuffle=True, random_state=1410)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = df.drop(columns=['PE'])\n",
    "y = df['PE']\n",
    "result_noise = np.zeros((times_cross_validation, len(clfs)))\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for j, clf_key in enumerate(clfs):\n",
    "        clf = copy.deepcopy(clfs[clf_key])\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        result_noise[i, j] = mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "for i, clf_key in enumerate(clfs):\n",
    "    print(f'MAE dla {clf_key} wynosi {round(result_noise[:,i].mean(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b939ace-3098-4aa7-8bf0-6cf648333719",
   "metadata": {},
   "source": [
    "# Analiza uzyskanych rezultatów\n",
    "Przeprowadzono eksperyment z zastosowanie algorytmów: regresji liniowej, regularyzacji Lasso, regularyzacji grzbietowej (Ridge) oraz SVM. Następnie autorską funkcją przeszukiwania siatkowego dostrojono parametry oraz zaszumiono dane. Całość sprawdzono wykonując trzykrotną walidację krzyżową. Wartości średnie uzyskanych błędów (MAE) przedstawiono poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e31051-691f-4a57-8fd8-7ecfb28a6d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------+------------+\n",
      "| Klasyfikator | Parametry domyślne | Po strojeniu | Zaszumione |\n",
      "+--------------+--------------------+--------------+------------+\n",
      "|  LinReg      |       3.628        |      -       |   35.915   |\n",
      "|  Ridge       |       3.632        |    3.625     |   35.915   |\n",
      "|  Lasso       |       5.616        |    3.629     |   35.915   |\n",
      "|  SVR         |       3.186        |    3.169     |   35.974   |\n",
      "+--------------+--------------------+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "t = PrettyTable(['Klasyfikator', 'Parametry domyślne', 'Po strojeniu', 'Zaszumione'])\n",
    "for i, clf_key in enumerate(clfs):\n",
    "    if i==0:\n",
    "        t.add_row([clf_key, round(result_basic[:,i].mean(), 3), '-', round(result_noise[:,i].mean(), 3)])\n",
    "    else:\n",
    "        t.add_row([clf_key, round(result_basic[:,i].mean(), 3), round(result_tun[:,i].mean(), 3), \n",
    "               round(result_noise[:,i].mean(), 3)])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c25a7-800a-4ad8-8eba-c339188df1fa",
   "metadata": {},
   "source": [
    "# Analiza wyników i wnioski\n",
    "\n",
    "Pierwotne wyniki (przed strojeniem hiperparametrów) uzyskane przy pomocy regresji liniowej okazały się lepsze niż przy użyciu regularyzacji Ridge i Lasso. Techniki te dają natomiast możliwość dostrojenia hiperparametrów. Po zastosowaniu strojenia algorytm Ridge okazał się lepszy od regresji liniowej. Lasso natomiast zmniejszył swój błąd o ponad 35% osiągając (w przybliżeniu do setnych części) wartość równie dobrą co regresja liniowa. Algorytm SVR cechujący się znacznie dłuższym czasem obliczeń (złożonością obliczeniową) od pozostałych algorytmów osiągnął najlepsze rezultaty. Dostrojenie hiperparametrów tylko poprawiło już i tak dobry wyniki. Po zaszumieniu danych poprzez przemnożenie danych przez wartości losowane z rozkładu normalnego o odchyleniu standardowym równym 0.1 i wartości oczekiwanej 1, otrzymano znaczne pogorszenie wyników. Mimo dostrojonych parametrów uzyskana wartość błędu dla danych zaszumionych była około dziesięciokrotnie większa niż w przypadku danych niezaszumionych.\n",
    "\n",
    "Przeprowadzone eksperymenty potwierdziły słuszność stosowania regularyzacji L1 i L2 nawet dla dużych zbiorów danych (9568 rekordów). Należy jednak pamiętać, że zastosowanie Lasso lub Ridge nie zawsze daje lepsze rezultaty w domyślnej implementacji. Często dopiero po dostrojeniu parametrów jesteśmy w stanie uzyskać rezultaty lepsze niż z użyciem regresji. Potwierdza to konieczność regularyzacji hiperparametrów.\n",
    "\n",
    "Ponadto zaszumione dane, czyli w istocie zwiększenie wariancji, ma kluczowy wpływ na wartość błędu. W przypadku silnie zaszumionych danych nawet mimo dostrojenia hiperparametrów nie jesteśmy w stanie uzyskać zadowalających wyników. Potwierdza to zwrot \"Garbage In, Garbage Out\" GIGO (pol. śmieci na wejściu – śmieci na wyjściu), która mówi, że mimo poprawnej procedury przetwarzania błędnych danych, uzyskane wyniki również będą błędne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4dd47d-cf53-42bc-a7e8-26f07096a2cc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
